{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases'\n",
    "                 + '/iris/iris.data', header=None)\n",
    "\n",
    "df = df.sample(frac=1, random_state=0) # shuffle\n",
    "\n",
    "df = df[df[4].isin(['Iris-virginica', 'Iris-versicolor'])] # filter\n",
    "\n",
    "# add label indices column , i.e convert flower label to number\n",
    "mapping = {k: v for v, k in enumerate(df[4].unique())}\n",
    "df[5] = (2* df[4].map(mapping)) -1 # labels in {-1,1}\n",
    "\n",
    "\n",
    "# normalise the data\n",
    "alldata = torch.tensor(df.iloc[:, [0,1,2,3]].values, dtype=torch.float)\n",
    "alldata = (alldata - alldata.mean(dim=0)) / alldata.var(dim=0)\n",
    "\n",
    "# create datasets\n",
    "\n",
    "target_tr = torch.tensor(df.iloc[:75, 5].values, dtype=torch.long)\n",
    "target_va = torch.tensor(df.iloc[75:, 5].values, dtype=torch.long)\n",
    "data_tr = alldata[:75]\n",
    "data_va = alldata[75:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def svm(x, w, b):\n",
    "    h = (x@w.t()).sum(1) + b\n",
    "    return h\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "def optimise_svm(X , y, sgd=True):\n",
    "    \n",
    "    dataset = data.TensorDataset(X,y) # create your datset\n",
    "    dataloader = data.DataLoader(dataset, batch_size=25, shuffle=True) \n",
    "    \n",
    "    w = torch.randn(1, 4, requires_grad=True)\n",
    "    b = torch.randn(1, requires_grad=True)\n",
    "    \n",
    "    if sgd:\n",
    "        opt = optim.SGD([w,b], lr=0.01, weight_decay=0.0001)\n",
    "    else:\n",
    "        opt = optim.Adam([w,b], lr=0.01, weight_decay=0.0001)\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        for batch in dataloader:\n",
    "            opt.zero_grad()\n",
    "            # YOUR CODE HERE\n",
    "            output = svm(batch[0], w, b)\n",
    "            loss = torch.mean(torch.clamp(1 - batch[1] * output, min=0))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "    return w,b\n",
    "            \n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def getAccuracy(w,b, X, y):\n",
    "    \n",
    "      h = (X@w.t()).sum(1) + b\n",
    "      predict = [1 if x > 0 else -1  for x in h.data]\n",
    "      score  = accuracy_score(y, predict)\n",
    "      return score\n",
    "      "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "SGD loss is 0.18527469038963318\n",
      "score is 0.9466666666666667\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "# create your dataloader\n",
    "w,b = optimise_svm(data_tr, target_tr)\n",
    "prediciton = svm(data_va,w,b)\n",
    "loss = torch.mean(torch.clamp(1 - target_va * prediciton, min=0))\n",
    "print(f\"SGD loss is {loss}\")\n",
    "score = getAccuracy(w,b, data_tr, target_tr)\n",
    "print(f\"score is {score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Adam loss is 0.16389106214046478\n",
      "score is 0.9733333333333334\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "w,b = optimise_svm(data_tr, target_tr, sgd=False)\n",
    "prediciton = svm(data_va,w,b)\n",
    "loss = torch.mean(torch.clamp(1 - target_va * prediciton, min=0))\n",
    "print(f\"Adam loss is {loss}\")\n",
    "score = getAccuracy(w,b, data_tr, target_tr)\n",
    "print(f\"score is {score}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "def sgd_mean(n):\n",
    "    scores = np.zeros(n)\n",
    "    test = 0\n",
    "    for x in range(n):\n",
    "        w,b = optimise_svm(data_tr, target_tr)\n",
    "        #pickle.dump( w, open( \"w_sgd.p\", \"wb\" ) )\n",
    "        #pickle.dump( b, open( \"b_sgd.p\", \"wb\" ) )\n",
    "        #w = pickle.load( open( \"w_sgd.p\", \"rb\" ) )\n",
    "        #b = pickle.load( open( \"b_sgd.p\", \"rb\" ) )\n",
    "        score = getAccuracy(w,b, data_va, target_va)\n",
    "        scores[x] = score\n",
    "        test += score\n",
    "    return scores\n",
    "\n",
    "def adam_mean(n):\n",
    "    scores = np.zeros(n)\n",
    "    for x in range(n):\n",
    "        w,b = optimise_svm(data_tr, target_tr, sgd=False)\n",
    "        #pickle.dump( w, open( \"w_adam.p\", \"wb\" ) )\n",
    "        #pickle.dump( b, open( \"b_adam.p\", \"wb\" ) )\n",
    "        #w = pickle.load( open( \"w_adam.p\", \"rb\" ) )\n",
    "        #b = pickle.load( open( \"b_adam.p\", \"rb\" ) )\n",
    "        score = getAccuracy(w,b, data_va, target_va)\n",
    "        scores[x] = score\n",
    "    print(f'Adam weights are {w} ')\n",
    "    return scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Adam weights are tensor([[-0.7973,  0.2295,  0.1306, -0.5493]], requires_grad=True) \n",
      "sgd mean is 0.9083999999999999 and adam mean is 0.8868\n",
      "sgd var is 0.0018014399999999994 and adam var is 0.0011537600000000006\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "sgd_mean_r = sgd_mean(100)\n",
    "adam_mean_r = adam_mean(100)\n",
    "\n",
    "adam_mean_arr = np.mean(adam_mean_r)\n",
    "sgd_mean_arr = np.mean(sgd_mean_r)\n",
    "\n",
    "adam_var = np.var(adam_mean_r)\n",
    "sgd_var = np.var(sgd_mean_r)\n",
    "\n",
    "print(f\"sgd mean is {sgd_mean_arr} and adam mean is {adam_mean_arr}\")\n",
    "print(f\"sgd var is {sgd_var} and adam var is {adam_var}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}